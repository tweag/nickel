//! The Nickel grammar.
//!
//! # Uniterm
//!
//! Nickel uses the uniterm grammar since
//! [RFC002](../rfcs/002-merge-types-terms-syntax.md). Uniterm is a common
//! grammar for both term and types. However, it is only a front-end: the rest of
//! the interpreter pipeline needs terms and types to be separate objects.
//!
//! Most of the time, grammar constructs determine unambiguously if an expression
//! should be considered as a type or a term. Typically, `e1 -> e2` will always
//! be a type, and `e1 + e2` a term. This doesn't contradict the fact that `e1 ->
//! e2` can be used as a term: the point is, even in the latter case, we still
//! parse `e1 -> e2` as a type first, and then derive a term from it wherever it
//! is used in a context expecting a term.
//!
//! This is not the case of all rules. Record literals and variables can both be
//! interpreted in a different way, depending on how their usage. In
//! `x : {foo : Num}`, `{foo : Num}` is interpreted as a record type. In `{foo :
//! Num}.foo`, it is a record literal with a missing definition for `foo`. The
//! first interpretation is **not** equivalent to first interpreting it as a
//! term, and then as a type.
//!
//! For those reasons, the `uniterm` module introduces a new AST definition, that
//! just wraps `RichTerm` and `Types`, together with dedicated variants for the
//! common constructs that are variables and records. As long as a common
//! construct is not used in a term or a type context, it can be still
//! interpreted as both. Once the usage determines the nature of a record or a
//! variable, it is converted to either a `RichTerm` or a `Types` (although still
//! possibly wrapped as a `UniTerm`).
//!
//! In consequence, this grammar uses three main types `RichTerm`, `Types` and
//! `UniTerm`, as well as conversion macros `AsTerm`, `AsType` and `AsUniTerm`.
//! Some rules that are known to only produce `RichTerm` or `Types` may have the
//! corresponding more precise return type. Other rules that produce or just
//! propagate general uniterms have to return a `UniTerm`.
use std::{
    collections::HashMap,
    ffi::OsString,
    convert::TryFrom,
};

use codespan::FileId;
use lalrpop_util::ErrorRecovery;

use super::{
    ExtendedTerm,
    utils::*,
    lexer::{Token, NormalToken, StringToken, MultiStringToken},
    error::ParseError,
    uniterm::*,
};

use crate::{
    mk_app,
    mk_opn,
    mk_fun,
    identifier::Ident,
    destruct::{Match, LastMatch, Destruct},
    term::{
        BinaryOp, RichTerm, Term, UnaryOp, StrChunk, MetaValue,
        MergePriority, Contract, NAryOp, RecordAttrs, SharedTerm,
        make as mk_term},
    types::{Types, AbsType},
    position::TermPos,
    label::Label,
};

grammar<'input, 'err>(src_id: FileId, errors: &'err mut Vec<ErrorRecovery<usize, Token<'input>, ParseError>>);

WithPos<Rule>: Rule = <l: @L> <t: Rule> <r: @R> => t.with_pos(mk_pos(src_id, l, r));

AsTerm<Rule>: RichTerm = <ut: WithPos<Rule>> =>?
    RichTerm::try_from(ut)
        .map_err(|e| lalrpop_util::ParseError::User{error: e});

AsType<Rule>: Types = <ut: WithPos<Rule>> =>?
    Types::try_from(ut)
        .map_err(|e| lalrpop_util::ParseError::User{error: e});

AsUniTerm<Rule>: UniTerm = <l: @L> <ut: Rule> <r: @R> =>
    UniTerm::from(ut).with_pos(mk_pos(src_id, l, r));

// A single type or meta-data annotation. The `Types` rule forbids the use of
// constructs that can themselves have annotation on the right, such as a `let`.
// Otherwise, `foo | let x = 1 in x : Num` is ambiguous (the annotation could be
// either `foo | (let x = 1 in (x : Num))` or `(foo | let x = 1 in x) : Num`).
//
// The rule to use for type annotations is given as a parameter. We always use a
// rule that is syntactically equivalent to the `Types` rule. The parameter is
// here to control if the type should have its variables fixed now (`FixedType`)
// or later (bare `Types`). Almost all rules are of the former kind, and use
// `FixedType` (see `FixedType` and `parser::utils::fix_type_vars`).
AnnotAtom<TypeRule>: MetaValue = {
    "|" <l: @L> <ty: TypeRule> <r: @R> => MetaValue {
        doc: None,
        types: None,
        contracts: vec![Contract {types: ty.clone(), label: mk_label(ty, src_id, l, r)}],
        priority: Default::default(),
        value: None,
    },
    "|" "default" => MetaValue {
        doc: None,
        types: None,
        contracts: Vec::new(),
        priority: MergePriority::Default,
        value: None
    },
    "|" "doc" <s: StaticString> => MetaValue {
        doc: Some(strip_indent_doc(s)),
        types: None,
        contracts: Vec::new(),
        priority: Default::default(),
        value: None,
    },
    ":" <l: @L> <ty: TypeRule> <r: @R> => MetaValue {
        doc: None,
        types: Some(Contract {types: ty.clone(), label: mk_label(ty, src_id, l, r)}),
        contracts: Vec::new(),
        priority: Default::default(),
        value: None,
    },
};

// An annotation, with possibly many metadata annotations chained.
Annot<TypeRule>: MetaValue = <anns: AnnotAtom<TypeRule>+> => anns.into_iter().fold(MetaValue::new(), MetaValue::flatten);

// A general term. Wrap the root of the grammar as a `RichTerm`.
pub Term: RichTerm = AsTerm<UniTerm>;

// A general type. Chosen such that it can't have top-level annotations.
// (see `AnnotAtom`)
Types: Types = {
    AsType<InfixExpr>,
    Forall,
};

// A type with type variables fixed. See `parser::utils::fix_type_vars`.
FixedType: Types = {
    <mut ty: Types> => {
        fix_type_vars(&mut ty);
        ty
    }
};

// Either a term or a top-level let-binding (a let-binding without an `in`).
// Used exclusively for the REPL.
pub ExtendedTerm: ExtendedTerm = {
    "let" <id: Ident> <meta: Annot<FixedType>?> "=" <t: Term> => {
        let t = if let Some(mut meta) = meta {
            let pos = t.pos;
            meta.value = Some(t);
            RichTerm::new(Term::MetaValue(meta), pos)
        }
        else {
            t
        };

        ExtendedTerm::ToplevelLet(id, t)
    },
    Term => ExtendedTerm::RichTerm(<>),
};

// A general uniterm. The root of the grammar.
UniTerm: UniTerm = {
    InfixExpr,
    AnnotatedInfixExpr,
    AsUniTerm<Forall>,
    "let" <pat:Pattern> <meta: Annot<FixedType>?>
        "=" <t1: Term>
        "in" <t2: Term> => {
        let t1 = if let Some(mut meta) = meta {
            let pos = t1.pos;
            meta.value = Some(t1);
            RichTerm::new(Term::MetaValue(meta), pos)
        }
        else {
            t1
        };

        UniTerm::from(mk_term::let_pat(pat.0, pat.1, t1, t2))
    },
    <l: @L> "fun" <pats: Pattern+> "=>" <t: Term> <r: @R> => {
        let pos = mk_pos(src_id, l, r);
        let rt = pats.into_iter().rev().fold(t, |t, (id, destruct)| RichTerm {
            term: SharedTerm::new(Term::FunPattern(id, destruct, t)),
            pos,
        });

        UniTerm::from(rt)
    },
    "switch" "{" <cases: (SwitchCase ",")*> <last: SwitchCase?> "}"
        <exp: Term> => {
        let mut acc = HashMap::with_capacity(cases.len());
        let mut default = None;

        for case in cases.into_iter().map(|x| x.0).chain(last.into_iter()) {
            match case {
                SwitchCase::Normal(id, t) => acc.insert(id, t),
                // If there are multiple default cases, the last one silently
                // erases the others. We should have a dedicated error for that
                SwitchCase::Default(t) => default.replace(t),
            };
        }

        UniTerm::from(
            Term::Switch(
                exp,
                acc,
                default,
            )
        )
    },
    "if" <cond: Term> "then" <t1: Term> "else" <t2: Term> =>
        UniTerm::from(mk_app!(Term::Op1(UnaryOp::Ite(), cond), t1, t2)),
    <l: @L> <t: !> <r: @R> => {
        let pos = mk_pos(src_id, l, r);
        errors.push(t);

        UniTerm::from(RichTerm::new(Term::ParseError, pos))
    },
};

AnnotatedInfixExpr: UniTerm = {
    <t: AsTerm<InfixExpr>> <mut meta: Annot<FixedType>> => {
        let pos = t.pos;
        meta.value = Some(t);
        UniTerm::from(RichTerm::new(Term::MetaValue(meta), pos))
    },
};

Forall: Types =
    "forall" <ids: Ident+> "." <ty: Types> => {
        ids.into_iter().rev().fold(
            ty,
            |acc, id| Types(AbsType::Forall(id, Box::new(acc)))
        )
    };

// A n-ary application-like expression (n may be 0, in the sense that this rule
// also includes previous levels).
Applicative: UniTerm = {
    "import" <s: StaticString> => UniTerm::from(Term::Import(OsString::from(s))),
    <t1: AsTerm<Applicative>> <t2: AsTerm<RecordOperand>> =>
        UniTerm::from(mk_app!(t1, t2)),
    <op: UOp> <t: AsTerm<RecordOperand>> => UniTerm::from(mk_term::op1(op, t)),
    <op: BOpPre> <t1: AsTerm<RecordOperand>> <t2: AsTerm<Atom>>
        => UniTerm::from(mk_term::op2(op, t1, t2)),
    NOpPre<AsTerm<RecordOperand>>,
    RecordOperand,
};

// The array type, potentially with an argument. Take precedence over
// application: `Array Foo` is always interpreted as the type `Array` parametrized
// by `Foo`, rather than the dynamic array type `Array Dyn` aliased to `Array` and
// seen as a contract applied to term `Foo`.
TypeArray: Types =
    "Array" <TypeArrayParam?> => {
        let ty = Box::new(<>.unwrap_or(Types(AbsType::Dyn())));
        Types(AbsType::Array(ty))
    };

// Possible parameter for the array type. It's `TypeAtom` augmented with an
// argument-less `Array`, which allows to parse `Array Array`. We can't add
// argument-less `Array` to type atoms directly, as it would make `Array Foo`
// ambiguous: could be parsed both as `Array` as a term applied to `Array` as a
// term, or as the parametrized type `Array Array`).
TypeArrayParam: Types = {
    "Array" => Types(AbsType::Array(Box::new(Types(AbsType::Dyn())))),
    AsType<Atom>,
};

RecordOperand: UniTerm = {
    Atom,
    AsUniTerm<RecordOperationChain>,
};

// A record operation chain, such as `{foo = data}.bar.baz`.
RecordOperationChain: RichTerm = {
    <t: AsTerm<RecordOperand>> "." <id: Ident> => mk_term::op1(UnaryOp::StaticAccess(id), t),
    <t: AsTerm<RecordOperand>> "." <t_id: WithPos<StrChunks>> => mk_access(t_id, t),
};

RowTail: Types = {
    <Ident> => Types(AbsType::Var(<>)),
    "Dyn" => Types(AbsType::Dyn()),
};

// A record, that can be later interpreted either as a record literal or as a
// record type.
UniRecord: UniRecord = {
   "{" <fields: (<RecordField> ",")*>
       <last_l: @L> <last: RecordLastField?> <last_r: @R>
       <tail_l: @L> <tail: (";" RowTail)?> <tail_r: @R>
   "}" => {
        let (last_field, attrs) = match last {
            Some(RecordLastField::Field(f)) => (Some(f), Default::default()),
            Some(RecordLastField::Ellipsis) =>
                (None, RecordAttrs { open: true }),
            None => (None, Default::default())
        };

        let pos_ellipsis = if attrs.open {
                mk_pos(src_id, last_l, last_r)
            }
            else {
                TermPos::None
            };

        let fields : Vec<_> = fields.into_iter().chain(last_field.into_iter()).collect();
        UniRecord {
            fields,
            tail: tail.map(|t| (t.1, mk_pos(src_id, tail_l, tail_r))),
            attrs,
            pos: TermPos::None,
            pos_ellipsis,
        }
    },
};

Atom: UniTerm = {
    "(" <AsUniTerm<CurriedOp>> ")",
    "(" <UniTerm> ")",
    "num literal" => UniTerm::from(Term::Num(<>)),
    "null" => UniTerm::from(Term::Null),
    Bool => UniTerm::from(Term::Bool(<>)),
    AsUniTerm<StrChunks>,
    Ident => UniTerm::from(UniTermNode::Var(<>)),
    UniRecord => UniTerm::from(UniTermNode::Record(<>)),
    "`" <EnumTag> => UniTerm::from(Term::Enum(<>)),
    "[" <terms: (<Term> ",")*> <last: Term?> "]" => {
        let terms : Vec<RichTerm> = terms.into_iter()
            .chain(last.into_iter()).collect();

        UniTerm::from(Term::Array(terms))
    },
    AsUniTerm<TypeAtom>,
};

// A record field definition. The is the only place where we don't fix the type
// variables inside the annotation right away (note the `Annot<Types>` instead
// of `Annot<Fixed>`).
RecordField: (FieldPath, RichTerm) = {
    <l: @L> <path: FieldPath> <ann: Annot<Types>?> <r: @R> <t: ("=" <Term>)?> => {
        let pos = t.as_ref()
            .map(|t| t.pos.clone())
            .unwrap_or(mk_pos(src_id, l, r));
        let term = if let Some(mut meta) = ann {
            meta.value = t;
            RichTerm::new(Term::MetaValue(meta), pos)
        } else {
            if let Some(deft) = t {
                deft
            } else {
                RichTerm::new(Term::Null, pos)
            }
        };

        (path, term)
    }
};

RecordLastField: RecordLastField = {
    <RecordField> => RecordLastField::Field(<>),
    ".." => RecordLastField::Ellipsis,
};

// A field path syntax in a field definition, as in `{foo."bar bar".baz = "value"}`.
FieldPath: Vec<FieldPathElem> = {
    <mut elems: (<FieldPathElem> ".")*> <last: FieldPathElem> => {
        elems.push(last);
        elems
    }
};

FieldPathElem: FieldPathElem = {
    <Ident> => FieldPathElem::Ident(<>),
    <WithPos<StrChunks>> => FieldPathElem::Expr(<>),
};

// Last field of a pattern
LastMatch: LastMatch = {
    Match => LastMatch::Match(<>),
    ".." <Ident?> => LastMatch::Ellipsis(<>),
};

// The right hand side of an `=` inside a destructuring pattern.
#[inline]
Pattern: (Option<Ident>,Destruct) = {
    <id:(<Ident> "@")?> <pat:Destruct> => (id,pat),
    Ident => (Some(<>),Destruct::Empty),
};

// A full pattern at the left-hand side of a destructuring let.
Destruct: Destruct = {
    <start: @L> "{" <mut matches: (<Match> ",")*> <last:LastMatch?> "}" <end: @R> => {
        let (open, rest) = match last {
	    Some(LastMatch::Match(m)) => {
	        matches.push(m);
	        (false,None)
	    },
	    Some(LastMatch::Ellipsis(rest)) => (true, rest),
	    _ => (false, None),
	};
	let span = mk_span(src_id, start, end);
	Destruct::Record{matches, open, rest, span}
    },
};

// A binding `ident = <pattern>` inside a destructuring pattern.
Match: Match = {
    <left:Ident> <anns: Annot<FixedType>?> <default: DefaultAnnot?> "=" <right: Pattern> => {
	let meta = match (default, anns) {
	    (Some(d), Some(m)) => MetaValue::flatten(d,m),
	    (Some(m),_) | (_,Some(m)) => m,
  	    _ => MetaValue {
	            contracts: vec![Contract{
	                types: Types(AbsType::Dyn().into()),
		        label: Label{span: left.pos.unwrap(), ..Default::default()},
		    }],
		    ..Default::default()
	    },
	};
	Match::Assign(left, meta, right)
    },
    <id:Ident> <anns: Annot<FixedType>?> <default: DefaultAnnot?> => {
	let meta = match (default, anns) {
	    (Some(d), Some(m)) => MetaValue::flatten(d,m),
	    (Some(m),_) | (_,Some(m)) => m,
  	    _ => MetaValue {
	            contracts: vec![Contract{
	                types: Types(AbsType::Dyn().into()),
		        label: Label{span: id.pos.unwrap(), ..Default::default()},
		    }],
		    ..Default::default()
	    },
	};
	Match::Simple(id, meta)
    },
};

// A default annotation in a pattern.
DefaultAnnot: MetaValue = "?" <t: Term> => MetaValue {
    priority: MergePriority::Default,
    value: Some(t),
    ..Default::default()
};

Ident: Ident = <l:@L> <i: "identifier"> <r:@R> =>
    Ident { label: i.to_string(), pos: mk_pos(src_id, l, r) };

Bool: bool = {
    "true" => true,
    "false" => false,
};

// Strings that support interpolation.
StrChunks: RichTerm = {
  <start: StringStart> <fst: ChunkLiteral?> <chunks: (ChunkExpr+ChunkLiteral)*> <lasts:ChunkExpr*> <end: StringEnd> => {
        debug_assert_eq!(start, end);

        let chunks: Vec<StrChunk<RichTerm>> = fst.into_iter()
            .map(StrChunk::Literal)
            .chain(chunks.into_iter()
                .map(|(mut es, s)| {
                    es.push(StrChunk::Literal(s));
                    es
                })
                .flatten())
            .chain(lasts.into_iter())
            .collect();

        let mut chunks = if start == StringKind::Multiline {
            strip_indent(chunks)
        }
        else {
            chunks
        };
        chunks.reverse();

        RichTerm::from(Term::StrChunks(chunks))
    },
};

StringStart : StringKind = {
    "\"" => StringKind::Standard,
    "m%\"" => StringKind::Multiline,
};

StringEnd : StringKind = {
    "\"" => StringKind::Standard,
    "\"%m" => StringKind::Multiline,
};

ChunkLiteral : String =
    <parts: ChunkLiteralPart+> => {
        parts.into_iter().fold(String::new(), |mut acc, part| {
            match part {
                ChunkLiteralPart::Str(s) => acc.push_str(s),
                ChunkLiteralPart::Char(c) => acc.push(c),
            };

            acc
        })
    };

ChunkExpr: StrChunk<RichTerm> = Interpolation <t: WithPos<Term>> "}" => StrChunk::Expr(t, 0);

Interpolation = { "%{", "multstr %{" };

StaticString: String = StringStart <s: ChunkLiteral?> StringEnd => s.unwrap_or_default();

EnumTag: Ident = {
    <Ident>,
    <StaticString> => <>.into(),
}

ChunkLiteralPart: ChunkLiteralPart<'input> = {
    "str literal" => ChunkLiteralPart::Str(<>),
    "multstr literal" => ChunkLiteralPart::Str(<>),
    "str esc char" => ChunkLiteralPart::Char(<>),
};

UOp: UnaryOp = {
    "is_num" => UnaryOp::IsNum(),
    "is_bool" => UnaryOp::IsBool(),
    "is_str" => UnaryOp::IsStr(),
    "is_fun" => UnaryOp::IsFun(),
    "is_array" => UnaryOp::IsArray(),
    "is_record" => UnaryOp::IsRecord(),
    "blame" => UnaryOp::Blame(),
    "chng_pol" => UnaryOp::ChangePolarity(),
    "polarity" => UnaryOp::Pol(),
    "go_dom" => UnaryOp::GoDom(),
    "go_codom" => UnaryOp::GoCodom(),
    "go_array" => UnaryOp::GoArray(),
    "wrap" => UnaryOp::Wrap(),
    "embed" <Ident> => UnaryOp::Embed(<>),
    "map"  => UnaryOp::ArrayMap(),
    "generate" => UnaryOp::ArrayGen(),
    "record_map" => UnaryOp::RecordMap(),
    "seq" => UnaryOp::Seq(),
    "deep_seq" => UnaryOp::DeepSeq(),
    "head" => UnaryOp::ArrayHead(),
    "tail" => UnaryOp::ArrayTail(),
    "length" => UnaryOp::ArrayLength(),
    "fields" => UnaryOp::FieldsOf(),
    "values" => UnaryOp::ValuesOf(),
    "str_trim" => UnaryOp::StrTrim(),
    "str_chars" => UnaryOp::StrChars(),
    "char_code" => UnaryOp::CharCode(),
    "char_from_code" => UnaryOp::CharFromCode(),
    "str_uppercase" => UnaryOp::StrUppercase(),
    "str_lowercase" => UnaryOp::StrLowercase(),
    "str_length" => UnaryOp::StrLength(),
    "str_from" => UnaryOp::ToStr(),
    "num_from" => UnaryOp::NumFromStr(),
    "enum_from" => UnaryOp::EnumFromStr(),
};

SwitchCase: SwitchCase = {
    "`" <id: EnumTag> "=>" <t: Term> => SwitchCase::Normal(id, t),
    "_" "=>" <t: Term> => SwitchCase::Default(<>),
}

// Infix operators by precedence levels. Lowest levels take precedence over
// highest ones.

InfixBOp2: BinaryOp = {
    "++" => BinaryOp::StrConcat(),
    "@" => BinaryOp::ArrayConcat(),
}

InfixBOp3: BinaryOp = {
    "*" => BinaryOp::Mult(),
    "/" => BinaryOp::Div(),
    "%" => BinaryOp::Modulo(),
}

InfixBOp4: BinaryOp = {
    "+" => BinaryOp::Plus(),
    "-" => BinaryOp::Sub(),
}

InfixUOp5: UnaryOp = {
    "!" => UnaryOp::BoolNot(),
}

InfixBOp6: BinaryOp = {
    "&" => BinaryOp::Merge(),
}

InfixBOp7: BinaryOp = {
    "<" => BinaryOp::LessThan(),
    "<=" => BinaryOp::LessOrEq(),
    ">" => BinaryOp::GreaterThan(),
    ">=" => BinaryOp::GreaterOrEq(),
}

InfixBOp8: BinaryOp = {
    "==" => BinaryOp::Eq(),
}

InfixLazyBOp9: UnaryOp = {
    "&&" => UnaryOp::BoolAnd(),
}

InfixLazyBOp10: UnaryOp = {
    "||" => UnaryOp::BoolOr(),
}

InfixBOp: BinaryOp = {
    InfixBOp2,
    InfixBOp3,
    InfixBOp4,
    InfixBOp6,
    InfixBOp7,
    InfixBOp8,
}

InfixUOpOrLazyBOp: UnaryOp = {
    InfixUOp5,
    InfixLazyBOp9,
    InfixLazyBOp10,
}

InfixOp: InfixOp = {
    <InfixBOp> => <>.into(),
    <InfixUOpOrLazyBOp> => <>.into(),
}

CurriedOp: RichTerm = {
    <l: @L> <op: InfixOp> <r: @R> =>
        op.eta_expand(mk_pos(src_id, l, r)),
    <l: @L> "|>" <r: @R> =>
        mk_fun!("x1", "x2",
            mk_app!(mk_term::var("x2"), mk_term::var("x1"))
            .with_pos(mk_pos(src_id, l, r))
        ),
    <l: @L> "!=" <r: @R> =>
        mk_fun!("x1", "x2",
            mk_term::op1(
                UnaryOp::BoolNot(),
                Term::Op2(BinaryOp::Eq(),
                    mk_term::var("x2"),
                    mk_term::var("x1")
                )
            )
            .with_pos(mk_pos(src_id, l, r))
        ),
    //<l: @L> "->" <r: @R> =>?
    //    UniTerm::from(
    //        mk_fun!("x1", "x2",
    //            mk_term::op1(
    //                UnaryOp::BoolNot(),
    //                Term::Op2(BinaryOp::Eq(),
    //                    mk_term::var("x2"),
    //                    mk_term::var("x1")
    //                )
    //            )
    //            .with_pos(mk_pos(src_id, l, r))
    //        )
    //    ),
}

InfixUOpApp<UOp, Expr>: UniTerm =
  <op: UOp> <t: AsTerm<Expr>> => UniTerm::from(mk_term::op1(op, t));

InfixBOpApp<BOp, LExpr, RExpr>: UniTerm =
  <t1: AsTerm<LExpr>> <op: BOp> <t2: AsTerm<RExpr>> =>
      UniTerm::from(mk_term::op2(op, t1, t2));

InfixLazyBOpApp<UOp, LExpr, RExpr>: UniTerm =
  <t1: AsTerm<LExpr>> <op: UOp> <t2: AsTerm<RExpr>> =>
    UniTerm::from(mk_app!(mk_term::op1(op, t1), t2));

InfixExpr: UniTerm = {
    #[precedence(level="0")]
    Applicative,
    AsUniTerm<TypeArray>,

    #[precedence(level="1")]
    "-" <AsTerm<InfixExpr>> =>
        UniTerm::from(mk_term::op2(BinaryOp::Sub(), Term::Num(0.0), <>)),

    #[precedence(level="2")] #[assoc(side="left")]
    InfixBOpApp<InfixBOp2, InfixExpr, InfixExpr>,

    #[precedence(level="3")] #[assoc(side="left")]
    InfixBOpApp<InfixBOp3, InfixExpr, InfixExpr>,

    #[precedence(level="4")] #[assoc(side="left")]
    InfixBOpApp<InfixBOp4, InfixExpr, InfixExpr>,

    #[precedence(level="5")]
    InfixUOpApp<InfixUOp5, InfixExpr>,

    #[precedence(level="6")] #[assoc(side="left")]
    InfixBOpApp<InfixBOp6, InfixExpr, InfixExpr>,
    <t1: AsTerm<InfixExpr>> "|>" <t2: AsTerm<InfixExpr>> =>
        UniTerm::from(mk_app!(t2, t1)),

    #[precedence(level="7")] #[assoc(side="left")]
    InfixBOpApp<InfixBOp7, InfixExpr, InfixExpr>,

    #[precedence(level="8")] #[assoc(side="left")]
    InfixBOpApp<InfixBOp8, InfixExpr, InfixExpr>,
    <t1: AsTerm<InfixExpr>> "!=" <t2: AsTerm<InfixExpr>> =>
        UniTerm::from(
            mk_term::op1(UnaryOp::BoolNot(), Term::Op2(BinaryOp::Eq(), t1, t2))
        ),

    #[precedence(level="9")] #[assoc(side="left")]
    InfixLazyBOpApp<InfixLazyBOp9, InfixExpr, InfixExpr>,

    #[precedence(level="10")] #[assoc(side="left")]
    InfixLazyBOpApp<InfixLazyBOp10, InfixExpr, InfixExpr>,

    #[precedence(level="11")] #[assoc(side="right")]
    <s: AsType<InfixExpr>> "->" <t: AsType<InfixExpr>> =>
        UniTerm::from(Types(AbsType::Arrow(Box::new(s), Box::new(t)))),
}

BOpPre: BinaryOp = {
    "assume" => BinaryOp::Assume(),
    "unwrap" => BinaryOp::Unwrap(),
    "go_field" => BinaryOp::GoField(),
    "has_field" => BinaryOp::HasField(),
    "elem_at" => BinaryOp::ArrayElemAt(),
    "tag" => BinaryOp::Tag(),
    "hash" => BinaryOp::Hash(),
    "serialize" => BinaryOp::Serialize(),
    "deserialize" => BinaryOp::Deserialize(),
    "pow" => BinaryOp::Pow(),
    "str_split" => BinaryOp::StrSplit(),
    "str_contains" => BinaryOp::StrContains(),
    "str_match" => BinaryOp::StrMatch(),
    "str_is_match" => BinaryOp::StrIsMatch(),
    "record_insert" => BinaryOp::DynExtend(),
    "record_remove" => BinaryOp::DynRemove(),
}

NOpPre<ArgRule>: UniTerm = {
    "str_replace" <t1: ArgRule> <t2: ArgRule> <t3: ArgRule> =>
        UniTerm::from(mk_opn!(NAryOp::StrReplace(), t1, t2, t3)),
    "str_replace_regex" <t1: ArgRule> <t2: ArgRule> <t3: ArgRule> =>
        UniTerm::from(mk_opn!(NAryOp::StrReplaceRegex(), t1, t2, t3)),
    "str_substr" <t1: ArgRule> <t2: ArgRule> <t3: ArgRule> =>
        UniTerm::from(mk_opn!(NAryOp::StrSubstr(), t1, t2, t3)),
}

TypeBuiltin: Types = {
    "Dyn" => Types(AbsType::Dyn()),
    "Num" => Types(AbsType::Num()),
    "Bool" => Types(AbsType::Bool()),
    "Str" => Types(AbsType::Str()),
}

TypeAtom: Types = {
    <TypeBuiltin>,
    "[|" <rows:(<EnumTag> ",")*> <last: (<EnumTag>)?> <tail: (";" <EnumTag>)?> "|]" => {
        let ty = rows.into_iter()
            .chain(last.into_iter())
            // As we build row types as a linked list via a fold on the original
            // iterator, the order of identifiers is reversed. This not a big deal
            // but it's less confusing to the user to print them in the original
            // order for error reporting.
            .rev()
            .fold(
                Types(
                    match tail {
                        Some(id) => AbsType::Var(id),
                        None => AbsType::RowEmpty(),
                    }
                ),
                |t, i| Types(AbsType::RowExtend(i, None, Box::new(t)))
            );
        Types(AbsType::Enum(Box::new(ty)))
    },
    "{" "_" ":" <Types> "}" => Types(AbsType::DynRecord(Box::new(<>))),
}

extern {
    type Location = usize;
    type Error = ParseError;

    enum Token<'input> {
        "identifier" => Token::Normal(NormalToken::Identifier(<&'input str>)),
        "str literal" => Token::Str(StringToken::Literal(<&'input str>)),
        "str esc char" => Token::Str(StringToken::EscapedChar(<char>)),
        "multstr literal" => Token::MultiStr(MultiStringToken::Literal(<&'input str>)),
        "num literal" => Token::Normal(NormalToken::NumLiteral(<f64>)),

        "if" => Token::Normal(NormalToken::If),
        "then" => Token::Normal(NormalToken::Then),
        "else" => Token::Normal(NormalToken::Else),
        "forall" => Token::Normal(NormalToken::Forall),
        "in" => Token::Normal(NormalToken::In),
        "let" => Token::Normal(NormalToken::Let),
        "switch" => Token::Normal(NormalToken::Switch),

        "null" => Token::Normal(NormalToken::Null),
        "true" => Token::Normal(NormalToken::True),
        "false" => Token::Normal(NormalToken::False),

        "?" => Token::Normal(NormalToken::QuestionMark),
        "," => Token::Normal(NormalToken::Comma),
        ";" => Token::Normal(NormalToken::Semicolon),
        ":" => Token::Normal(NormalToken::Colon),
        "$" => Token::Normal(NormalToken::Dollar),
        "=" => Token::Normal(NormalToken::Equals),
        "!=" => Token::Normal(NormalToken::NotEquals),
        "&" => Token::Normal(NormalToken::Ampersand),
        "." => Token::Normal(NormalToken::Dot),
        "%{" => Token::Str(StringToken::Interpolation),
        "multstr %{" => Token::MultiStr(MultiStringToken::Interpolation),

        "+" => Token::Normal(NormalToken::Plus),
        "-" => Token::Normal(NormalToken::Minus),
        "*" => Token::Normal(NormalToken::Times),
        "/" => Token::Normal(NormalToken::Div),
        "%" => Token::Normal(NormalToken::Percent),
        "++" => Token::Normal(NormalToken::DoublePlus),
        "==" => Token::Normal(NormalToken::DoubleEq),
        "@" => Token::Normal(NormalToken::At),
        "&&" => Token::Normal(NormalToken::DoubleAnd),
        "||" => Token::Normal(NormalToken::DoublePipe),
        "!" => Token::Normal(NormalToken::Bang),
        ".." => Token::Normal(NormalToken::Ellipsis),

        "fun" => Token::Normal(NormalToken::Fun),
        "import" => Token::Normal(NormalToken::Import),
        "|" => Token::Normal(NormalToken::Pipe),
        "|>" => Token::Normal(NormalToken::RightPipe),
        "->" => Token::Normal(NormalToken::SimpleArrow),
        "=>" => Token::Normal(NormalToken::DoubleArrow),
        "`" => Token::Normal(NormalToken::Backtick),
        "_" => Token::Normal(NormalToken::Underscore),
        "\"" => Token::Normal(NormalToken::DoubleQuote),
        "\"%m" => Token::MultiStr(MultiStringToken::End),
        "m%\"" => Token::Normal(NormalToken::MultiStringStart(<usize>)),

        "Num" => Token::Normal(NormalToken::Num),
        "Dyn" => Token::Normal(NormalToken::Dyn),
        "Str" => Token::Normal(NormalToken::Str),
        "Bool" => Token::Normal(NormalToken::Bool),
        "Array" => Token::Normal(NormalToken::Array),

        "tag" => Token::Normal(NormalToken::Tag),
        "is_num" => Token::Normal(NormalToken::IsNum),
        "is_bool" => Token::Normal(NormalToken::IsBool),
        "is_str" => Token::Normal(NormalToken::IsStr),
        "is_fun" => Token::Normal(NormalToken::IsFun),
        "is_array" => Token::Normal(NormalToken::IsArray),
        "is_record" => Token::Normal(NormalToken::IsRecord),
        "assume" => Token::Normal(NormalToken::Assume),
        "blame" => Token::Normal(NormalToken::Blame),
        "chng_pol" => Token::Normal(NormalToken::ChangePol),
        "polarity" => Token::Normal(NormalToken::Polarity),
        "go_dom" => Token::Normal(NormalToken::GoDom),
        "go_codom" => Token::Normal(NormalToken::GoCodom),
        "go_array" => Token::Normal(NormalToken::GoArray),
        "go_field" => Token::Normal(NormalToken::GoField),
        "wrap" => Token::Normal(NormalToken::Wrap),
        "unwrap" => Token::Normal(NormalToken::Unwrap),
        "embed" => Token::Normal(NormalToken::Embed),
        "record_map" => Token::Normal(NormalToken::RecordMap),
        "record_insert" => Token::Normal(NormalToken::RecordInsert),
        "record_remove" => Token::Normal(NormalToken::RecordRemove),
        "seq" => Token::Normal(NormalToken::Seq),
        "deep_seq" => Token::Normal(NormalToken::DeepSeq),
        "head" => Token::Normal(NormalToken::Head),
        "tail" => Token::Normal(NormalToken::Tail),
        "length" => Token::Normal(NormalToken::Length),
        "fields" => Token::Normal(NormalToken::FieldsOf),
        "values" => Token::Normal(NormalToken::ValuesOf),
        "pow" => Token::Normal(NormalToken::Pow),

        "has_field" => Token::Normal(NormalToken::HasField),
        "map" => Token::Normal(NormalToken::Map),
        "generate" => Token::Normal(NormalToken::ArrayGen),
        "elem_at" => Token::Normal(NormalToken::ElemAt),
        "merge" => Token::Normal(NormalToken::Merge),
        "default" => Token::Normal(NormalToken::Default),
        "doc" => Token::Normal(NormalToken::Doc),

        "hash" => Token::Normal(NormalToken::OpHash),
        "serialize" => Token::Normal(NormalToken::Serialize),
        "deserialize" => Token::Normal(NormalToken::Deserialize),
        "str_split" => Token::Normal(NormalToken::StrSplit),
        "str_trim" => Token::Normal(NormalToken::StrTrim),
        "str_chars" => Token::Normal(NormalToken::StrChars),
        "char_code" => Token::Normal(NormalToken::CharCode),
        "char_from_code" => Token::Normal(NormalToken::CharFromCode),
        "str_uppercase" => Token::Normal(NormalToken::StrUppercase),
        "str_lowercase" => Token::Normal(NormalToken::StrLowercase),
        "str_contains" => Token::Normal(NormalToken::StrContains),
        "str_replace" => Token::Normal(NormalToken::StrReplace),
        "str_replace_regex" => Token::Normal(NormalToken::StrReplaceRegex),
        "str_is_match" => Token::Normal(NormalToken::StrIsMatch),
        "str_match" => Token::Normal(NormalToken::StrMatch),
        "str_length" => Token::Normal(NormalToken::StrLength),
        "str_substr" => Token::Normal(NormalToken::StrSubstr),
        "str_from" => Token::Normal(NormalToken::ToStr),
        "num_from" => Token::Normal(NormalToken::NumFromStr),
        "enum_from" => Token::Normal(NormalToken::EnumFromStr),

        "{" => Token::Normal(NormalToken::LBrace),
        "}" => Token::Normal(NormalToken::RBrace),
        "[" => Token::Normal(NormalToken::LBracket),
        "]" => Token::Normal(NormalToken::RBracket),
        "(" => Token::Normal(NormalToken::LParen),
        ")" => Token::Normal(NormalToken::RParen),
        "<" => Token::Normal(NormalToken::LAngleBracket),
        "<=" => Token::Normal(NormalToken::LessOrEq),
        ">" => Token::Normal(NormalToken::RAngleBracket),
        ">=" => Token::Normal(NormalToken::GreaterOrEq),
        "[|" => Token::Normal(NormalToken::EnumOpen),
        "|]" => Token::Normal(NormalToken::EnumClose),
    }
}
